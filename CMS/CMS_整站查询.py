import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from io import StringIO

headers = {
    "Content-Type": "application/x-www-form-urlencoded",
    "User-Agent": "Mozilla/5.0",
    "Origin": "https://cms.imyfone.club",
    "Referer": "https://cms.imyfone.club/imyfoneadmin/manage_all/index.html",
    "Cookie": "admin_username=daihh; PHPSESSID=e8aolv03vcqkpapbkcijcnvsig; site_id=15"
}

url_list = [
"https://es.imyfone.com/mac-data-recovery/show-hidden-files-mac/"
]

all_records = []

for query_url in url_list:
    payload = {
        "page_category_type": "",
        "product": "",
        "status": "",
        "start_time": "",
        "end_time": "",
        "show_paging": "0",
        "id": "",
        "article_title": "",
        "full_page_url": "",
        "page_full_content": query_url,
        "operation": "",
        "limit": "1500"
    }

    response = requests.post(
        url="https://cms.imyfone.club/imyfoneadmin/manage_all/index.html",
        headers=headers,
        data=payload
    )

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        tables = soup.find_all('table')
        if tables:
            html_table = str(tables[0])
            df = pd.read_html(StringIO(html_table))[0]
            if 'URL' in df.columns:
                temp_df = df[['URL']].copy()
                temp_df['æŸ¥è¯¢é¡µé¢'] = query_url
                all_records.append(temp_df)
                print(f"âœ… æˆåŠŸæå– URLï¼š{query_url}")
            else:
                print(f"âš ï¸ è¡¨æ ¼ä¸­æ—  URL å­—æ®µï¼š{query_url}")
        else:
            print(f"âš ï¸ æœªå‘ç°è¡¨æ ¼ï¼š{query_url}")
    else:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼š{query_url}ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")

    time.sleep(1)

if all_records:
    result_df = pd.concat(all_records, ignore_index=True)
    result_df = result_df.drop_duplicates()

    # è°ƒæ•´åˆ—é¡ºåº
    result_df = result_df[['æŸ¥è¯¢é¡µé¢', 'URL']]

    # å¯¹â€œæŸ¥è¯¢é¡µé¢â€åˆ—åˆ†ç»„ï¼Œé™¤ç¬¬ä¸€æ¡å¤–è®¾ä¸ºç©º
    def blank_except_first(group):
        group = group.copy()
        group.loc[group.index[1:], 'æŸ¥è¯¢é¡µé¢'] = ''
        return group

    result_df = result_df.groupby('æŸ¥è¯¢é¡µé¢', group_keys=False).apply(blank_except_first)

    result_df.to_excel("æå–ç»“æœ_URLåŠæŸ¥è¯¢é¡µé¢_åˆ†ç»„æ˜¾ç¤º.xlsx", index=False)
    print("ğŸ“ å·²ä¿å­˜ä¸ºï¼šæå–ç»“æœ_URLåŠæŸ¥è¯¢é¡µé¢_åˆ†ç»„æ˜¾ç¤º.xlsx")
else:
    print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½• URL")
